{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "\"\"\" [MobileNets: Efficient Convolutional Neural Networks for\n",
    "   Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf))\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from . import get_submodules_from_kwargs\n",
    "from . import imagenet_utils\n",
    "from .imagenet_utils import decode_predictions\n",
    "from .imagenet_utils import _obtain_input_shape\n",
    "\n",
    "\n",
    "BASE_WEIGHT_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                    'releases/download/v0.6/')\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "\n",
    "\n",
    "def preprocess_input(x, **kwargs):\n",
    "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
    "    # Returns\n",
    "        Preprocessed array.\n",
    "    \"\"\"\n",
    "    return imagenet_utils.preprocess_input(x, mode='tf', **kwargs)\n",
    "\n",
    "\n",
    "def MobileNet(input_shape=None,\n",
    "              alpha=1.0,\n",
    "              depth_multiplier=1,\n",
    "              dropout=1e-3,\n",
    "              include_top=True,\n",
    "              weights='imagenet',\n",
    "              input_tensor=None,\n",
    "              pooling=None,\n",
    "              classes=1000,\n",
    "              **kwargs):\n",
    "    \"\"\"Instantiates the MobileNet architecture.\n",
    "    # Arguments\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)`\n",
    "            (with `channels_last` data format)\n",
    "            or (3, 224, 224) (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        depth_multiplier: depth multiplier for depthwise convolution\n",
    "            (also called the resolution multiplier)\n",
    "        dropout: dropout rate\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor (i.e. output of\n",
    "            `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model\n",
    "                will be the 4D tensor output of the\n",
    "                last convolutional block.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional block, and thus\n",
    "                the output of the model will be a\n",
    "                2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n",
    "                         'as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape and default size.\n",
    "    if input_shape is None:\n",
    "        default_size = 224\n",
    "    else:\n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            rows = input_shape[1]\n",
    "            cols = input_shape[2]\n",
    "        else:\n",
    "            rows = input_shape[0]\n",
    "            cols = input_shape[1]\n",
    "\n",
    "        if rows == cols and rows in [128, 160, 192, 224]:\n",
    "            default_size = rows\n",
    "        else:\n",
    "            default_size = 224\n",
    "\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=default_size,\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        row_axis, col_axis = (0, 1)\n",
    "    else:\n",
    "        row_axis, col_axis = (1, 2)\n",
    "    rows = input_shape[row_axis]\n",
    "    cols = input_shape[col_axis]\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        if depth_multiplier != 1:\n",
    "            raise ValueError('If imagenet weights are being loaded, '\n",
    "                             'depth multiplier must be 1')\n",
    "\n",
    "        if alpha not in [0.25, 0.50, 0.75, 1.0]:\n",
    "            raise ValueError('If imagenet weights are being loaded, '\n",
    "                             'alpha can be one of'\n",
    "                             '`0.25`, `0.50`, `0.75` or `1.0` only.')\n",
    "\n",
    "        if rows != cols or rows not in [128, 160, 192, 224]:\n",
    "            if rows is None:\n",
    "                rows = 224\n",
    "                warnings.warn('MobileNet shape is undefined.'\n",
    "                              ' Weights for input shape '\n",
    "                              '(224, 224) will be loaded.')\n",
    "            else:\n",
    "                raise ValueError('If imagenet weights are being loaded, '\n",
    "                                 'input must have a static square shape '\n",
    "                                 '(one of (128, 128), (160, 160), '\n",
    "                                 '(192, 192), or (224, 224)). '\n",
    "                                 'Input shape provided = %s' % (input_shape,))\n",
    "\n",
    "    if backend.image_data_format() != 'channels_last':\n",
    "        warnings.warn('The MobileNet family of models is only available '\n",
    "                      'for the input data format \"channels_last\" '\n",
    "                      '(width, height, channels). '\n",
    "                      'However your settings specify the default '\n",
    "                      'data format \"channels_first\" (channels, width, height).'\n",
    "                      ' You should set `image_data_format=\"channels_last\"` '\n",
    "                      'in your Keras config located at ~/.keras/keras.json. '\n",
    "                      'The model being returned right now will expect inputs '\n",
    "                      'to follow the \"channels_last\" data format.')\n",
    "        backend.set_image_data_format('channels_last')\n",
    "        old_data_format = 'channels_first'\n",
    "    else:\n",
    "        old_data_format = None\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = _conv_block(img_input, 32, alpha, strides=(2, 2))\n",
    "    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=2)\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=4)\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=6)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=12)\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "\n",
    "    if include_top:\n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            shape = (int(1024 * alpha), 1, 1)\n",
    "        else:\n",
    "            shape = (1, 1, int(1024 * alpha))\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Reshape(shape, name='reshape_1')(x)\n",
    "        x = layers.Dropout(dropout, name='dropout')(x)\n",
    "        x = layers.Conv2D(classes, (1, 1),\n",
    "                          padding='same',\n",
    "                          name='conv_preds')(x)\n",
    "        x = layers.Activation('softmax', name='act_softmax')(x)\n",
    "        x = layers.Reshape((classes,), name='reshape_2')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            raise ValueError('Weights for \"channels_first\" format '\n",
    "                             'are not available.')\n",
    "        if alpha == 1.0:\n",
    "            alpha_text = '1_0'\n",
    "        elif alpha == 0.75:\n",
    "            alpha_text = '7_5'\n",
    "        elif alpha == 0.50:\n",
    "            alpha_text = '5_0'\n",
    "        else:\n",
    "            alpha_text = '2_5'\n",
    "\n",
    "        if include_top:\n",
    "            model_name = 'mobilenet_%s_%d_tf.h5' % (alpha_text, rows)\n",
    "            weight_path = BASE_WEIGHT_PATH + model_name\n",
    "            weights_path = keras_utils.get_file(model_name,\n",
    "                                                weight_path,\n",
    "                                                cache_subdir='models')\n",
    "        else:\n",
    "            model_name = 'mobilenet_%s_%d_tf_no_top.h5' % (alpha_text, rows)\n",
    "            weight_path = BASE_WEIGHT_PATH + model_name\n",
    "            weights_path = keras_utils.get_file(model_name,\n",
    "                                                weight_path,\n",
    "                                                cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    if old_data_format:\n",
    "        backend.set_image_data_format(old_data_format)\n",
    "    return model\n",
    "\n",
    "\n",
    "def _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1)):\n",
    "    \"\"\"Adds an initial convolution layer (with batch normalization and relu6).\n",
    "    # Arguments\n",
    "        inputs: Input tensor of shape `(rows, cols, 3)`\n",
    "            (with `channels_last` data format) or\n",
    "            (3, rows, cols) (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(224, 224, 3)` would be one valid value.\n",
    "        filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number of output filters in the convolution).\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution\n",
    "            along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, filters, new_rows, new_cols)`\n",
    "        if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, new_rows, new_cols, filters)`\n",
    "        if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to stride.\n",
    "    # Returns\n",
    "        Output tensor of block.\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "    filters = int(filters * alpha)\n",
    "    x = layers.ZeroPadding2D(padding=((0, 1), (0, 1)), name='conv1_pad')(inputs)\n",
    "    x = layers.Conv2D(filters, kernel,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      strides=strides,\n",
    "                      name='conv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n",
    "    return layers.ReLU(6., name='conv1_relu')(x)\n",
    "\n",
    "\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n",
    "                          depth_multiplier=1, strides=(1, 1), block_id=1):\n",
    "    \"\"\"Adds a depthwise convolution block.\n",
    "    A depthwise convolution block consists of a depthwise conv,\n",
    "    batch normalization, relu6, pointwise convolution,\n",
    "    batch normalization and relu6 activation.\n",
    "    # Arguments\n",
    "        inputs: Input tensor of shape `(rows, cols, channels)`\n",
    "            (with `channels_last` data format) or\n",
    "            (channels, rows, cols) (with `channels_first` data format).\n",
    "        pointwise_conv_filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number of output filters in the pointwise convolution).\n",
    "        alpha: controls the width of the network.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        depth_multiplier: The number of depthwise convolution output channels\n",
    "            for each input channel.\n",
    "            The total number of depthwise convolution output\n",
    "            channels will be equal to `filters_in * depth_multiplier`.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution\n",
    "            along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "        block_id: Integer, a unique identification designating\n",
    "            the block number.\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, channels, rows, cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, rows, cols, channels)` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, filters, new_rows, new_cols)`\n",
    "        if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, new_rows, new_cols, filters)`\n",
    "        if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to stride.\n",
    "    # Returns\n",
    "        Output tensor of block.\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    if strides == (1, 1):\n",
    "        x = inputs\n",
    "    else:\n",
    "        x = layers.ZeroPadding2D(((0, 1), (0, 1)),\n",
    "                                 name='conv_pad_%d' % block_id)(inputs)\n",
    "    x = layers.DepthwiseConv2D((3, 3),\n",
    "                               padding='same' if strides == (1, 1) else 'valid',\n",
    "                               depth_multiplier=depth_multiplier,\n",
    "                               strides=strides,\n",
    "                               use_bias=False,\n",
    "                               name='conv_dw_%d' % block_id)(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = layers.ReLU(6., name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = layers.Conv2D(pointwise_conv_filters, (1, 1),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      strides=(1, 1),\n",
    "                      name='conv_pw_%d' % block_id)(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                  name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return layers.ReLU(6., name='conv_pw_%d_relu' % block_id)(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
